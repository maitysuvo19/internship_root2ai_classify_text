{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Root2ai_classification_bagofwords.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN6YGHmcNAFbbf0NmDSq2Sx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maitysuvo19/internship_root2ai_classify_text/blob/main/Root2ai_classification_bagofwords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubyHrlrzKcRM"
      },
      "source": [
        "# Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N76uPfmKIh1",
        "outputId": "02a50a8c-e9e4-4c4a-d424-4c823771a7f9"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#import feature extraction methods from sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction import stop_words\n",
        "\n",
        "#pre-processing of text\n",
        "import string\n",
        "import re\n",
        "\n",
        "#import classifiers from sklearn\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "#import different metrics to evaluate the classifiers\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix,classification_report \n",
        "from sklearn import metrics\n",
        "\n",
        "#import time function from time module to track the training duration\n",
        "from time import time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR7rQRGbK2gC"
      },
      "source": [
        "df=pd.read_csv('/content/root2ai - Data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "GoQyJH9YLGQ-",
        "outputId": "3c99ca39-4446-447e-937e-ecf9a047cd70"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>reserve bank forming expert committee based in...</td>\n",
              "      <td>Blockchain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>director could play role financial system</td>\n",
              "      <td>Blockchain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>preliminary discuss secure transaction study r...</td>\n",
              "      <td>Blockchain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>security indeed prove essential transforming f...</td>\n",
              "      <td>Blockchain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bank settlement normally take three days based...</td>\n",
              "      <td>Blockchain</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text      Target\n",
              "0  reserve bank forming expert committee based in...  Blockchain\n",
              "1          director could play role financial system  Blockchain\n",
              "2  preliminary discuss secure transaction study r...  Blockchain\n",
              "3  security indeed prove essential transforming f...  Blockchain\n",
              "4  bank settlement normally take three days based...  Blockchain"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T4vmFwQO7--",
        "outputId": "0ae01eb9-5855-43fb-e926-8846683b294b"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 22704 entries, 0 to 22703\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Text    22701 non-null  object\n",
            " 1   Target  22704 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 354.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx8FVoe6LOzA",
        "outputId": "a72d8075-3b34-4978-c435-a644072073bc"
      },
      "source": [
        "df[\"Target\"].value_counts()/df.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FinTech             0.376630\n",
              "Cyber Security      0.116279\n",
              "Bigdata             0.099850\n",
              "Reg Tech            0.097163\n",
              "credit reporting    0.076991\n",
              "Blockchain          0.060562\n",
              "Neobanks            0.047084\n",
              "Microservices       0.043032\n",
              "Stock Trading       0.034663\n",
              "Robo Advising       0.032461\n",
              "Data Security       0.015284\n",
              "Name: Target, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "xCt-BGIqLm_c",
        "outputId": "5f612dc2-3eb1-4008-cc92-50c138b5045a"
      },
      "source": [
        "df['Target'] =df.Target.map({'FinTech':1, 'Cyber Security':2,'Bigdata':3,'Reg Tech':4,'credit reporting':5,'Blockchain':6,'Neobanks':7,'Microservices':8,'Stock Trading':9,'Robo Advising':10,'Data Security':11})\n",
        "df = df[[\"Text\",\"Target\"]]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>reserve bank forming expert committee based in...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>director could play role financial system</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>preliminary discuss secure transaction study r...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>security indeed prove essential transforming f...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bank settlement normally take three days based...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Target\n",
              "0  reserve bank forming expert committee based in...       6\n",
              "1          director could play role financial system       6\n",
              "2  preliminary discuss secure transaction study r...       6\n",
              "3  security indeed prove essential transforming f...       6\n",
              "4  bank settlement normally take three days based...       6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTWtf13YNyej"
      },
      "source": [
        "# Text Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkSzmeQdN5BT"
      },
      "source": [
        "Typical steps involve tokenization, lower casing, removing, stop words, punctuation markers etc, and vectorization. Other processes such as stemming/lemmatization can also be performed. Here, we are performing the following steps: removing br tags, punctuation, numbers, and stopwords. While we are using sklearn's list of stopwords, there are several other stop word lists (e.g., from NLTK) or sometimes, custom stopword lists are needed depending on the task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScHKjznPN1WF"
      },
      "source": [
        "stopwords = stop_words.ENGLISH_STOP_WORDS\n",
        "def clean(doc): #doc is a string of text\n",
        "    doc = doc.replace(\"</br>\", \" \") #This text contains a lot of <br/> tags.\n",
        "    doc = \"\".join([char for char in doc if char not in string.punctuation and not char.isdigit()])\n",
        "    doc = \" \".join([token for token in doc.split() if token not in stopwords])\n",
        "    #remove punctuation and numbers\n",
        "    return doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDVqAQ16ODUT"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH78U7PBN_Or",
        "outputId": "4d13e001-2973-465d-b879-02498aa604b7"
      },
      "source": [
        "#Step 1: train-test split\n",
        "X = df.Text.fillna(' ') #the column text contains textual data to extract features from\n",
        "y = df.Target #this is the column we are learning to predict. \n",
        "print(X.shape, y.shape)\n",
        "# split X and y into training and testing sets. By default, it splits 75% training and 25% test\n",
        "#random_state=1 for reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22704,) (22704,)\n",
            "(17028,) (17028,)\n",
            "(5676,) (5676,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Wr_FAqnOfA9",
        "outputId": "9ae640a2-eb42-420e-80c2-eece01861306"
      },
      "source": [
        "#Step 2-3: Preprocess and Vectorize train and test data\n",
        "vect = CountVectorizer(preprocessor=clean) #instantiate a vectoriezer\n",
        "X_train_dtm = vect.fit_transform(X_train)#use it to extract features from training data\n",
        "#transform testing data (using training data's features)\n",
        "X_test_dtm = vect.transform(X_test)\n",
        "print(X_train_dtm.shape, X_test_dtm.shape)\n",
        "#i.e., the dimension of our feature vector is 31195!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17028, 11329) (5676, 11329)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd5piKtYQgki"
      },
      "source": [
        "Naive Bayse Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHqgGggCQcYd",
        "outputId": "cd04a156-a550-4146-9f0f-959196f71edc"
      },
      "source": [
        "#Step 3: Train the classifier and predict for test data\n",
        "nb = MultinomialNB() #instantiate a Multinomial Naive Bayes model\n",
        "%time nb.fit(X_train_dtm, y_train)\n",
        "y_pred_class = nb.predict(X_test_dtm)#make class predictions for X_test_dtm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 15.5 ms, sys: 1.98 ms, total: 17.5 ms\n",
            "Wall time: 20.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56o3ZCGtQnbC",
        "outputId": "d7de825a-7cbe-411d-9a73-1238759ccaf2"
      },
      "source": [
        "#calculate evaluation measures:\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred_class))\n",
        "print(classification_report(y_test, y_pred_class))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.6719520789288231\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.59      0.92      0.72      2168\n",
            "           2       0.63      0.54      0.58       655\n",
            "           3       0.86      0.74      0.80       577\n",
            "           4       0.90      0.80      0.85       532\n",
            "           5       0.75      0.53      0.62       424\n",
            "           6       0.80      0.35      0.49       355\n",
            "           7       0.81      0.08      0.15       272\n",
            "           8       0.93      0.50      0.65       225\n",
            "           9       0.82      0.50      0.62       188\n",
            "          10       0.83      0.14      0.23       185\n",
            "          11       1.00      0.09      0.17        95\n",
            "\n",
            "    accuracy                           0.67      5676\n",
            "   macro avg       0.81      0.47      0.53      5676\n",
            "weighted avg       0.72      0.67      0.64      5676\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOfWfHjs6g1m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_lcLjEgQ_E5"
      },
      "source": [
        "Logistic Regression Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0VyCipEREOA",
        "outputId": "6099596b-b12c-4979-d9b6-72e63f144cee"
      },
      "source": [
        "logreg = LogisticRegression(class_weight=\"balanced\") #instantiate a logistic regression model\n",
        "logreg.fit(X_train_dtm, y_train) #fit the model with training data\n",
        "\n",
        "#Make predictions on test data\n",
        "y_pred_class = logreg.predict(X_test_dtm)\n",
        "\n",
        "#calculate evaluation measures:\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred_class))\n",
        "print(classification_report(y_test, y_pred_class))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.6005990133897111\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.77      0.50      0.61      2168\n",
            "           2       0.53      0.58      0.56       655\n",
            "           3       0.63      0.83      0.71       577\n",
            "           4       0.90      0.76      0.82       532\n",
            "           5       0.60      0.67      0.63       424\n",
            "           6       0.51      0.60      0.55       355\n",
            "           7       0.31      0.56      0.39       272\n",
            "           8       0.55      0.62      0.58       225\n",
            "           9       0.43      0.66      0.52       188\n",
            "          10       0.36      0.55      0.43       185\n",
            "          11       0.32      0.39      0.35        95\n",
            "\n",
            "    accuracy                           0.60      5676\n",
            "   macro avg       0.54      0.61      0.56      5676\n",
            "weighted avg       0.65      0.60      0.61      5676\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-2fIwT_RSdE"
      },
      "source": [
        "Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bzo6hh_RNhe",
        "outputId": "b18c7724-b5ec-4825-f1de-3a0db5c91200"
      },
      "source": [
        "svm = LinearSVC(class_weight='balanced') #instantiate a support vector machine model\n",
        "svm.fit(X_train_dtm, y_train) #fit the model with training data\n",
        "\n",
        "#Make predictions on test data\n",
        "y_pred_class = svm.predict(X_test_dtm)\n",
        "\n",
        "#calculate evaluation measures:\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred_class))\n",
        "print(classification_report(y_test, y_pred_class))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.6201550387596899\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.71      0.61      0.66      2168\n",
            "           2       0.55      0.59      0.57       655\n",
            "           3       0.78      0.74      0.76       577\n",
            "           4       0.89      0.78      0.83       532\n",
            "           5       0.56      0.66      0.60       424\n",
            "           6       0.52      0.55      0.53       355\n",
            "           7       0.34      0.46      0.39       272\n",
            "           8       0.60      0.59      0.59       225\n",
            "           9       0.44      0.63      0.52       188\n",
            "          10       0.33      0.49      0.40       185\n",
            "          11       0.32      0.36      0.34        95\n",
            "\n",
            "    accuracy                           0.62      5676\n",
            "   macro avg       0.55      0.59      0.56      5676\n",
            "weighted avg       0.64      0.62      0.63      5676\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Mefw9xERqZf"
      },
      "source": [
        "Our large feature vector could be creating a lot of noise in the form of very rarely occurring features that are not useful for learning. Let us change the count vectorizer to take a certain number of features as maximum.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC_BBarRR1tF",
        "outputId": "08602f2f-0fb1-415a-a895-715418da40df"
      },
      "source": [
        "#Step 2-3: Preprocess and Vectorize train and test data\n",
        "vect = CountVectorizer(preprocessor=clean,max_features=5000) #instantiate a vectoriezer\n",
        "X_train_dtm = vect.fit_transform(X_train)#use it to extract features from training data\n",
        "#transform testing data (using training data's features)\n",
        "X_test_dtm = vect.transform(X_test)\n",
        "print(X_train_dtm.shape, X_test_dtm.shape)\n",
        "#i.e., the dimension of our feature vector is 5000!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17028, 5000) (5676, 5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEvNjMWzR8Zm"
      },
      "source": [
        "Naive Bayse Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jthc2223R3zL",
        "outputId": "7ed388dc-40fe-446e-d0b6-735d2833c7e2"
      },
      "source": [
        "#Step 3: Train the classifier and predict for test data\n",
        "nb = MultinomialNB() #instantiate a Multinomial Naive Bayes model\n",
        "%time nb.fit(X_train_dtm, y_train)\n",
        "y_pred_class = nb.predict(X_test_dtm)#make class predictions for X_test_dtm\n",
        "#calculate evaluation measures:\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred_class))\n",
        "print(classification_report(y_test, y_pred_class))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 14.8 ms, sys: 398 µs, total: 15.2 ms\n",
            "Wall time: 15.1 ms\n",
            "Accuracy:  0.6717758985200846\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.63      0.85      0.72      2168\n",
            "           2       0.58      0.57      0.58       655\n",
            "           3       0.79      0.70      0.74       577\n",
            "           4       0.87      0.77      0.82       532\n",
            "           5       0.68      0.59      0.63       424\n",
            "           6       0.73      0.49      0.59       355\n",
            "           7       0.57      0.19      0.28       272\n",
            "           8       0.82      0.63      0.71       225\n",
            "           9       0.73      0.57      0.64       188\n",
            "          10       0.61      0.24      0.35       185\n",
            "          11       0.67      0.11      0.18        95\n",
            "\n",
            "    accuracy                           0.67      5676\n",
            "   macro avg       0.70      0.52      0.57      5676\n",
            "weighted avg       0.68      0.67      0.66      5676\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf2FU4azSJo7"
      },
      "source": [
        "Logistic Regression Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRZEsWcBSKsZ",
        "outputId": "d08c11a2-6fd8-4a6a-b11e-28bd1bbc19f1"
      },
      "source": [
        "logreg = LogisticRegression(class_weight=\"balanced\") #instantiate a logistic regression model\n",
        "logreg.fit(X_train_dtm, y_train) #fit the model with training data\n",
        "\n",
        "#Make predictions on test data\n",
        "y_pred_class = logreg.predict(X_test_dtm)\n",
        "\n",
        "#calculate evaluation measures:\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred_class))\n",
        "print(classification_report(y_test, y_pred_class))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.5863284002818887\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.77      0.48      0.59      2168\n",
            "           2       0.53      0.57      0.55       655\n",
            "           3       0.59      0.82      0.69       577\n",
            "           4       0.88      0.74      0.80       532\n",
            "           5       0.60      0.66      0.63       424\n",
            "           6       0.49      0.61      0.55       355\n",
            "           7       0.30      0.55      0.39       272\n",
            "           8       0.52      0.61      0.57       225\n",
            "           9       0.43      0.67      0.53       188\n",
            "          10       0.35      0.55      0.43       185\n",
            "          11       0.29      0.39      0.33        95\n",
            "\n",
            "    accuracy                           0.59      5676\n",
            "   macro avg       0.52      0.60      0.55      5676\n",
            "weighted avg       0.64      0.59      0.59      5676\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrVBxGF8SWyk"
      },
      "source": [
        "Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8DM8_6FSRn2",
        "outputId": "335aa986-37bd-48f3-bb8f-76ca603cb37f"
      },
      "source": [
        "svm = LinearSVC(class_weight='balanced') #instantiate a support vector machine model\n",
        "svm.fit(X_train_dtm, y_train) #fit the model with training data\n",
        "\n",
        "#Make predictions on test data\n",
        "y_pred_class = svm.predict(X_test_dtm)\n",
        "\n",
        "#calculate evaluation measures:\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred_class))\n",
        "print(classification_report(y_test, y_pred_class))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.602184637068358\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.75      0.56      0.64      2168\n",
            "           2       0.55      0.58      0.56       655\n",
            "           3       0.67      0.81      0.73       577\n",
            "           4       0.86      0.77      0.81       532\n",
            "           5       0.55      0.63      0.59       424\n",
            "           6       0.50      0.54      0.52       355\n",
            "           7       0.32      0.47      0.38       272\n",
            "           8       0.51      0.56      0.54       225\n",
            "           9       0.43      0.62      0.51       188\n",
            "          10       0.31      0.47      0.38       185\n",
            "          11       0.26      0.36      0.30        95\n",
            "\n",
            "    accuracy                           0.60      5676\n",
            "   macro avg       0.52      0.58      0.54      5676\n",
            "weighted avg       0.63      0.60      0.61      5676\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}