{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Root2ai_classification_deeplearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1QlNYGe95CiIMwuVddfd3djoKbqX753it",
      "authorship_tag": "ABX9TyO7ZwrvpmNmwe+r2oEgN3zi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maitysuvo19/internship_root2ai_classify_text/blob/main/Root2ai_classification_deeplearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5jLlsex4lD_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQB-5-3P5rpJ"
      },
      "source": [
        "df=pd.read_csv('/content/root2ai - Data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "nF_76gEx57Rh",
        "outputId": "1ebecb35-c214-441e-d552-c6649a2a97d7"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>reserve bank forming expert committee based in...</td>\n",
              "      <td>Blockchain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>director could play role financial system</td>\n",
              "      <td>Blockchain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>preliminary discuss secure transaction study r...</td>\n",
              "      <td>Blockchain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>security indeed prove essential transforming f...</td>\n",
              "      <td>Blockchain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bank settlement normally take three days based...</td>\n",
              "      <td>Blockchain</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text      Target\n",
              "0  reserve bank forming expert committee based in...  Blockchain\n",
              "1          director could play role financial system  Blockchain\n",
              "2  preliminary discuss secure transaction study r...  Blockchain\n",
              "3  security indeed prove essential transforming f...  Blockchain\n",
              "4  bank settlement normally take three days based...  Blockchain"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "icgULLAy6AKo",
        "outputId": "244fd370-afc1-4109-dd32-bd96248749cc"
      },
      "source": [
        "df=df.dropna()\n",
        "df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>reserve bank forming expert committee based in...</td>\n",
              "      <td>Blockchain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>director could play role financial system</td>\n",
              "      <td>Blockchain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>preliminary discuss secure transaction study r...</td>\n",
              "      <td>Blockchain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>security indeed prove essential transforming f...</td>\n",
              "      <td>Blockchain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bank settlement normally take three days based...</td>\n",
              "      <td>Blockchain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22696</th>\n",
              "      <td>fourth study discusses blockchain technology e...</td>\n",
              "      <td>Reg Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22697</th>\n",
              "      <td>book finishes stating biggest issue emerging F...</td>\n",
              "      <td>Reg Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22698</th>\n",
              "      <td>people culture cess</td>\n",
              "      <td>Reg Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22699</th>\n",
              "      <td>author challenges execu tive lead change stop ...</td>\n",
              "      <td>Reg Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22700</th>\n",
              "      <td>change data driven culture come bottom must start</td>\n",
              "      <td>Reg Tech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22701 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    Text      Target\n",
              "0      reserve bank forming expert committee based in...  Blockchain\n",
              "1              director could play role financial system  Blockchain\n",
              "2      preliminary discuss secure transaction study r...  Blockchain\n",
              "3      security indeed prove essential transforming f...  Blockchain\n",
              "4      bank settlement normally take three days based...  Blockchain\n",
              "...                                                  ...         ...\n",
              "22696  fourth study discusses blockchain technology e...    Reg Tech\n",
              "22697  book finishes stating biggest issue emerging F...    Reg Tech\n",
              "22698                                people culture cess    Reg Tech\n",
              "22699  author challenges execu tive lead change stop ...    Reg Tech\n",
              "22700  change data driven culture come bottom must start    Reg Tech\n",
              "\n",
              "[22701 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISBj3AT96H7h",
        "outputId": "69d62598-bb41-48b8-ba57-833aca122dee"
      },
      "source": [
        "df.isnull().any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text      False\n",
              "Target    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kl1HtGV6LzB",
        "outputId": "2d99f235-5723-45ed-b118-00db9e4569f6"
      },
      "source": [
        "df[\"Target\"].value_counts()/df.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FinTech             0.376679\n",
              "Cyber Security      0.116294\n",
              "Bigdata             0.099863\n",
              "Reg Tech            0.097176\n",
              "credit reporting    0.077001\n",
              "Blockchain          0.060570\n",
              "Neobanks            0.047090\n",
              "Microservices       0.042906\n",
              "Stock Trading       0.034668\n",
              "Robo Advising       0.032466\n",
              "Data Security       0.015286\n",
              "Name: Target, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ATvkWGX66RgZ",
        "outputId": "a58a5930-e014-4e3c-c706-23647185bd99"
      },
      "source": [
        "df['Target'] =df.Target.map({'FinTech':0, 'Cyber Security':1,'Bigdata':2,'Reg Tech':3,'credit reporting':4,'Blockchain':5,'Neobanks':6,'Microservices':7,'Stock Trading':8,'Robo Advising':9,'Data Security':10})\n",
        "df = df[[\"Text\",\"Target\"]]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>reserve bank forming expert committee based in...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>director could play role financial system</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>preliminary discuss secure transaction study r...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>security indeed prove essential transforming f...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bank settlement normally take three days based...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Target\n",
              "0  reserve bank forming expert committee based in...       5\n",
              "1          director could play role financial system       5\n",
              "2  preliminary discuss secure transaction study r...       5\n",
              "3  security indeed prove essential transforming f...       5\n",
              "4  bank settlement normally take three days based...       5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "FQKlgG1q6pSB",
        "outputId": "be8c459f-af05-4079-a275-6101a585a807"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>reserve bank forming expert committee based in...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>director could play role financial system</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>preliminary discuss secure transaction study r...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>security indeed prove essential transforming f...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bank settlement normally take three days based...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Target\n",
              "0  reserve bank forming expert committee based in...       5\n",
              "1          director could play role financial system       5\n",
              "2  preliminary discuss secure transaction study r...       5\n",
              "3  security indeed prove essential transforming f...       5\n",
              "4  bank settlement normally take three days based...       5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbe8PqRe65ZC"
      },
      "source": [
        "import sklearn\n",
        "#from sklearn.cross_validation import train_test_split\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07ITPkT369Rp",
        "outputId": "1a3aec58-6f34-4d3b-d46a-cbe0175160df"
      },
      "source": [
        "#splitting the data set\n",
        "train, test = train_test_split(df, test_size=0.25)\n",
        "print(\"Train DF: \",train.shape)\n",
        "print(\"Test DF: \",test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train DF:  (17025, 2)\n",
            "Test DF:  (5676, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kRlCxn57FMZ"
      },
      "source": [
        "#Make the necessary imports\n",
        "import sys\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM\n",
        "from keras.models import Model, Sequential\n",
        "from keras.initializers import Constant"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIaKX23Y7Ji5"
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NUM_WORDS = 20000 \n",
        "EMBEDDING_DIM = 100 \n",
        "VALIDATION_SPLIT = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVGaMAAP7NM5"
      },
      "source": [
        "GLOVE_DIR='/content/drive/MyDrive/nlp data/glove.6B.100d.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8wn8e2z7Qj7"
      },
      "source": [
        "labels_index = {'FinTech':0, 'Cyber Security':1,'Bigdata':2,'Reg Tech':3,'credit reporting':4,'Blockchain':5,'Neobanks':6,'Microservices':7,'Stock Trading':8,'Robo Advising':9,'Data Security':10}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMrHsQeK7Qi5"
      },
      "source": [
        "train_texts=train['Text'].tolist()\n",
        "train_labels=train['Target'].tolist()\n",
        "test_texts=test['Text'].tolist()\n",
        "test_labels=test['Target'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dfb3bnp7u26",
        "outputId": "2ef38130-33ba-4d50-fc9e-435992b5c81c"
      },
      "source": [
        "#Just to see how the data looks like. \n",
        "print(train_texts[0])\n",
        "print(train_labels[0])\n",
        "print(test_texts[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial capital start phase bank could pose greater risk financial progressively reduce amount funds available\n",
            "0\n",
            "promise data\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGnwvXKT7zUJ",
        "outputId": "6c76a56e-41ba-47e7-8410-3a6cc189ccbf"
      },
      "source": [
        "#Vectorize these text samples into a 2D integer tensor using Keras Tokenizer\n",
        "#Tokenizer is fit on training data only, and that is used to tokenize both train and test data.\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts) #Converting text to a vector of word indexes\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10271 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjEyJf-S75mp",
        "outputId": "eba096df-e5af-449e-8116-bbf4459099f6"
      },
      "source": [
        "#Converting this to sequences to be fed into neural network. Max seq. len is 1000 as set earlier\n",
        " #initial padding of 0s, until vector is of size MAX_SEQUENCE_LENGTH\n",
        "trainvalid_data = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "trainvalid_labels = to_categorical(np.asarray(train_labels))\n",
        "test_labels = to_categorical(np.asarray(test_labels))\n",
        "\n",
        "# split the training data into a training set and a validation set\n",
        "indices = np.arange(trainvalid_data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "trainvalid_data = trainvalid_data[indices]\n",
        "trainvalid_labels = trainvalid_labels[indices]\n",
        "num_validation_samples = int(VALIDATION_SPLIT * trainvalid_data.shape[0])\n",
        "x_train = trainvalid_data[:-num_validation_samples]\n",
        "y_train = trainvalid_labels[:-num_validation_samples]\n",
        "x_val = trainvalid_data[-num_validation_samples:]\n",
        "y_val = trainvalid_labels[-num_validation_samples:]\n",
        "#This is the data we will use for CNN and RNN training\n",
        "print('Splitting the train data into train and valid is done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Splitting the train data into train and valid is done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03BtjgZB7_dZ",
        "outputId": "eaad4b0b-a2bf-46f0-d52a-07aa50f6e3e9"
      },
      "source": [
        "print('Preparing embedding matrix.')\n",
        "\n",
        "# first, build index mapping words in the embeddings set\n",
        "# to their embedding vector\n",
        "embeddings_index = {}\n",
        "with open(GLOVE_DIR) as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print('Found %s word vectors in Glove embeddings.' % len(embeddings_index))\n",
        "#print(embeddings_index[\"google\"])\n",
        "\n",
        "# prepare embedding matrix - rows are the words from word_index, columns are the embeddings of that word from glove.\n",
        "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i > MAX_NUM_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# load these pre-trained word embeddings into an Embedding layer\n",
        "# note that we set trainable = False so as to keep the embeddings fixed\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            EMBEDDING_DIM,\n",
        "                            embeddings_initializer=Constant(embedding_matrix),\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)\n",
        "print(\"Preparing of embedding matrix is done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing embedding matrix.\n",
            "Found 400000 word vectors in Glove embeddings.\n",
            "Preparing of embedding matrix is done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5B4Zi4bsKjC"
      },
      "source": [
        "# 1D CNN Model with pre-trained embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5BIekyf8HnZ",
        "outputId": "52523fb7-fc24-4782-fe85-8ebe702f8267"
      },
      "source": [
        "print('Define a 1D CNN model.')\n",
        "\n",
        "cnnmodel = Sequential()\n",
        "cnnmodel.add(embedding_layer)\n",
        "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
        "cnnmodel.add(MaxPooling1D(5))\n",
        "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
        "cnnmodel.add(MaxPooling1D(5))\n",
        "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
        "cnnmodel.add(GlobalMaxPooling1D())\n",
        "cnnmodel.add(Dense(128, activation='relu'))\n",
        "cnnmodel.add(Dense(len(labels_index), activation='softmax'))\n",
        "\n",
        "cnnmodel.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])\n",
        "#Train the model. Tune to validation set. \n",
        "cnnmodel.fit(x_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=5, validation_data=(x_val, y_val))\n",
        "#Evaluate on test set:\n",
        "score, acc = cnnmodel.evaluate(test_data, test_labels)\n",
        "print('Test accuracy with CNN:', acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Define a 1D CNN model.\n",
            "Epoch 1/5\n",
            "107/107 [==============================] - 38s 44ms/step - loss: 2.0121 - acc: 0.3809 - val_loss: 1.7603 - val_acc: 0.4564\n",
            "Epoch 2/5\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 1.6329 - acc: 0.4950 - val_loss: 1.5965 - val_acc: 0.5037\n",
            "Epoch 3/5\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 1.4497 - acc: 0.5463 - val_loss: 1.5791 - val_acc: 0.5160\n",
            "Epoch 4/5\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 1.3103 - acc: 0.5810 - val_loss: 1.5697 - val_acc: 0.5151\n",
            "Epoch 5/5\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 1.1930 - acc: 0.6163 - val_loss: 1.4846 - val_acc: 0.5398\n",
            "178/178 [==============================] - 1s 7ms/step - loss: 1.4978 - acc: 0.5400\n",
            "Test accuracy with CNN: 0.5399929285049438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyQYkCCXsfsA"
      },
      "source": [
        "# 1D CNN model with training your own embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIiOPwfFsFb0",
        "outputId": "04f34572-5352-4c82-cc04-0c8442ad7e04"
      },
      "source": [
        "print(\"Defining and training a CNN model, training embedding layer on the fly instead of using pre-trained embeddings\")\n",
        "cnnmodel = Sequential()\n",
        "cnnmodel.add(Embedding(MAX_NUM_WORDS, 128))\n",
        "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
        "cnnmodel.add(MaxPooling1D(5))\n",
        "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
        "cnnmodel.add(MaxPooling1D(5))\n",
        "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
        "cnnmodel.add(GlobalMaxPooling1D())\n",
        "cnnmodel.add(Dense(128, activation='relu'))\n",
        "cnnmodel.add(Dense(len(labels_index), activation='softmax'))\n",
        "\n",
        "cnnmodel.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])\n",
        "#Train the model. Tune to validation set. \n",
        "cnnmodel.fit(x_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=5, validation_data=(x_val, y_val))\n",
        "#Evaluate on test set:\n",
        "score, acc = cnnmodel.evaluate(test_data, test_labels)\n",
        "print('Test accuracy with CNN:', acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defining and training a CNN model, training embedding layer on the fly instead of using pre-trained embeddings\n",
            "Epoch 1/5\n",
            "107/107 [==============================] - 8s 70ms/step - loss: 2.0768 - acc: 0.3586 - val_loss: 1.8881 - val_acc: 0.3997\n",
            "Epoch 2/5\n",
            "107/107 [==============================] - 7s 67ms/step - loss: 1.7713 - acc: 0.4270 - val_loss: 1.6335 - val_acc: 0.5019\n",
            "Epoch 3/5\n",
            "107/107 [==============================] - 7s 67ms/step - loss: 1.4385 - acc: 0.5538 - val_loss: 1.5251 - val_acc: 0.5278\n",
            "Epoch 4/5\n",
            "107/107 [==============================] - 7s 67ms/step - loss: 1.2467 - acc: 0.5987 - val_loss: 1.6369 - val_acc: 0.4881\n",
            "Epoch 5/5\n",
            "107/107 [==============================] - 7s 67ms/step - loss: 1.1095 - acc: 0.6467 - val_loss: 1.6735 - val_acc: 0.5228\n",
            "178/178 [==============================] - 1s 7ms/step - loss: 1.6259 - acc: 0.5217\n",
            "Test accuracy with CNN: 0.5216701626777649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrTpDszDtV86"
      },
      "source": [
        "# LSTM Model with training your own embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8tFqWSxtXy-",
        "outputId": "5bab2f9a-5bdf-4e3b-b119-31afaf5ed57c"
      },
      "source": [
        "print(\"Defining and training an LSTM model, training embedding layer on the fly\")\n",
        "\n",
        "#model\n",
        "rnnmodel = Sequential()\n",
        "rnnmodel.add(Embedding(MAX_NUM_WORDS, 128))\n",
        "rnnmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "rnnmodel.add(Dense(11, activation='softmax'))\n",
        "rnnmodel.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "print('Training the RNN')\n",
        "\n",
        "rnnmodel.fit(x_train, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=5,\n",
        "          validation_data=(x_val, y_val))\n",
        "score, acc = rnnmodel.evaluate(test_data, test_labels,\n",
        "                            batch_size=32)\n",
        "print('Test accuracy with RNN:', acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defining and training an LSTM model, training embedding layer on the fly\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Training the RNN\n",
            "Epoch 1/5\n",
            "426/426 [==============================] - 1380s 3s/step - loss: 1.9260 - accuracy: 0.4056 - val_loss: 1.2508 - val_accuracy: 0.6132\n",
            "Epoch 2/5\n",
            "426/426 [==============================] - 1381s 3s/step - loss: 0.9668 - accuracy: 0.6969 - val_loss: 1.0930 - val_accuracy: 0.6655\n",
            "Epoch 3/5\n",
            "426/426 [==============================] - 1378s 3s/step - loss: 0.6241 - accuracy: 0.8029 - val_loss: 1.1311 - val_accuracy: 0.6529\n",
            "Epoch 4/5\n",
            "426/426 [==============================] - 1371s 3s/step - loss: 0.4284 - accuracy: 0.8627 - val_loss: 1.2478 - val_accuracy: 0.6455\n",
            "Epoch 5/5\n",
            "426/426 [==============================] - 1378s 3s/step - loss: 0.3218 - accuracy: 0.8986 - val_loss: 1.3538 - val_accuracy: 0.6335\n",
            "178/178 [==============================] - 38s 213ms/step - loss: 1.3160 - accuracy: 0.6506\n",
            "Test accuracy with RNN: 0.650634229183197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e-BSI5KIL1V"
      },
      "source": [
        "LSTM Model using pre-trained Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IgkRxdiIG2e",
        "outputId": "5baa0aec-59ad-44ca-b5d9-14dbd8966841"
      },
      "source": [
        "print(\"Defining and training an LSTM model, using pre-trained embedding layer\")\n",
        "\n",
        "rnnmodel2 = Sequential()\n",
        "rnnmodel2.add(embedding_layer)\n",
        "rnnmodel2.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "rnnmodel2.add(Dense(11, activation='softmax'))\n",
        "rnnmodel2.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "print('Training the RNN')\n",
        "\n",
        "rnnmodel2.fit(x_train, y_train,\n",
        "          batch_size=256,\n",
        "          epochs=5,\n",
        "          validation_data=(x_val, y_val))\n",
        "score, acc = rnnmodel2.evaluate(test_data, test_labels,\n",
        "                            batch_size=256)\n",
        "print('Test accuracy with RNN:', acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defining and training an LSTM model, using pre-trained embedding layer\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Training the RNN\n",
            "Epoch 1/5\n",
            "54/54 [==============================] - 180s 3s/step - loss: 2.0296 - accuracy: 0.3652 - val_loss: 1.6569 - val_accuracy: 0.4849\n",
            "Epoch 2/5\n",
            "54/54 [==============================] - 175s 3s/step - loss: 1.6122 - accuracy: 0.4954 - val_loss: 1.4690 - val_accuracy: 0.5272\n",
            "Epoch 3/5\n",
            "54/54 [==============================] - 176s 3s/step - loss: 1.4779 - accuracy: 0.5249 - val_loss: 1.4043 - val_accuracy: 0.5539\n",
            "Epoch 4/5\n",
            "54/54 [==============================] - 176s 3s/step - loss: 1.4038 - accuracy: 0.5509 - val_loss: 1.3733 - val_accuracy: 0.5583\n",
            "Epoch 5/5\n",
            "54/54 [==============================] - 175s 3s/step - loss: 1.3568 - accuracy: 0.5679 - val_loss: 1.3318 - val_accuracy: 0.5645\n",
            "23/23 [==============================] - 6s 255ms/step - loss: 1.3580 - accuracy: 0.5514\n",
            "Test accuracy with RNN: 0.5514446496963501\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}